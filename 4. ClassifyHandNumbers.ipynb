{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of fingers classification\n",
    "\n",
    "In this notebook a small example where number of fingers shown on a hand is classified. \n",
    "\n",
    "The main idea of this notebook is to show the potential of using pretrained models and how these models can be tuned to make another classification task then they where originally trained for.\n",
    "\n",
    "In this case we use the VGG16 application in Keras and use the weights achived when trained on the Imagenet dataset containg 10000000 images. The whole training session takes 2-3 weeks on an average CPU.\n",
    "\n",
    "The convolutional filters used to create the fature maps are quite general and no matter what type of images you have those might be quite good at extract some information.\n",
    "\n",
    "Images was collected with a webacam and the aim of the images is to have enough images to make an application with a reasonoble accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sjohanss\\documents\\utbildning\\region västerbotten - ai - lab 4\\test_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\sjohanss\\documents\\utbildning\\region västerbotten - ai - lab 4\\test_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\sjohanss\\documents\\utbildning\\region västerbotten - ai - lab 4\\test_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\sjohanss\\documents\\utbildning\\region västerbotten - ai - lab 4\\test_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\sjohanss\\documents\\utbildning\\region västerbotten - ai - lab 4\\test_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\sjohanss\\documents\\utbildning\\region västerbotten - ai - lab 4\\test_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\sjohanss\\documents\\utbildning\\region västerbotten - ai - lab 4\\test_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\sjohanss\\documents\\utbildning\\region västerbotten - ai - lab 4\\test_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\sjohanss\\documents\\utbildning\\region västerbotten - ai - lab 4\\test_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\sjohanss\\documents\\utbildning\\region västerbotten - ai - lab 4\\test_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\sjohanss\\documents\\utbildning\\region västerbotten - ai - lab 4\\test_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\sjohanss\\documents\\utbildning\\region västerbotten - ai - lab 4\\test_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#First load all packages\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Input, Flatten, Dropout, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import json\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from PIL import Image\n",
    "\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "from io import StringIO, BytesIO\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues,\n",
    "                          fig_size=10):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]*100\n",
    "    else:\n",
    "        cm = cm\n",
    "    \n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(fig_size,fig_size))\n",
    "    im = ax.imshow(cm,norm=LogNorm(), cmap=cmap,\n",
    "                interpolation='nearest')\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ylim=ax.get_ylim()\n",
    "    ax.set(\n",
    "        ylim=ylim,\n",
    "        xticks=np.arange(cm.shape[1]),\n",
    "        yticks=np.arange(cm.shape[0]),\n",
    "        # ... and label them with the respective list entries\n",
    "        xticklabels=classes, \n",
    "        yticklabels=classes,\n",
    "        title=title,\n",
    "        ylabel='True label',\n",
    "        xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "              rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.1f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "def plot_errors(x_test, y_test, output,n_max=600):\n",
    "    \"\"\" Function the reporting in a script in order to\n",
    "    breake the script if it is estimated to take to long time\"\"\"\n",
    "    n_not_corr = np.sum(output != y_test )\n",
    "    n = int(np.ceil(np.sqrt(n_not_corr)))\n",
    "    j = 0\n",
    "    if n_not_corr > n_max:\n",
    "        print('more then '+str(n_max),n**2)\n",
    "        return\n",
    "    f, ax = plt.subplots(n, n, figsize=(25, 25))\n",
    "    ax = ax.flatten()\n",
    "    \n",
    "    for i in range(np.shape(output)[0]):\n",
    "            if output[i]!=y_test[i]:\n",
    "                ax[j].set_title(str(y_test[i]) + ' as ' + str(output[i]))\n",
    "                ax[j].imshow(x_test[i,:,:,:])\n",
    "                ax[j].axis('off')\n",
    "                j+=1\n",
    "    for x in ax.ravel():\n",
    "        x.axis(\"off\")\n",
    "    plt.subplots_adjust(bottom=-0.09, wspace=0.03)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "def load_zipped_images(zipfile):\n",
    "    np.random.seed(9001)\n",
    "    resp = urlopen(\"https://github.com/simjoh/AI-Lab-Neural-Net-and-Python/blob/master/handTracking/Images.zip?raw=true\")\n",
    "    archive = ZipFile(BytesIO(resp.read()))\n",
    "    image_paths=archive.namelist()\n",
    "    i=0\n",
    "    labels=[]\n",
    "    data = np.zeros((np.shape(image_paths)[0], 224, 224, 3), dtype='float32')\n",
    "    \n",
    "    for entry in archive.infolist():\n",
    "        if entry.filename[-4:]=='.jpg':\n",
    "            with archive.open(entry) as file:\n",
    "                img = Image.open(file)\n",
    "                img2 = np.array(img)\n",
    "                img3 = img2 + int(np.random.random()*100-50)\n",
    "                np.clip(img3, 0, 255,out=img3)\n",
    "                img3 = img3/255.\n",
    "                data[i, :, :, :] = img3\n",
    "                label_split = entry.filename.split('/')#[7:13]\n",
    "                labels.append(label_split[1])\n",
    "                i+=1\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the github account.\n",
    "data, data_labels = load_zipped_images(\"https://github.com/simjoh/AI-Lab-Neural-Net-and-Python/blob/master/handTracking/Images.zip?raw=true\")#\n",
    "eval_data, eval_labels = load_zipped_images(\"https://github.com/simjoh/AI-Lab-Neural-Net-and-Python/blob/master/handTracking/EvaluationImages.zip?raw=true\")# load_images(\"./handTracking/EvaluationImages/\",200)\n",
    "# Convert labels from strings to numbers\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(data_labels)\n",
    "conv_labels = le.transform(data_labels) \n",
    "conv_labels_eval = le.transform(eval_labels)\n",
    "\n",
    "\n",
    "# Delete images that are just zeros\n",
    "data = data[0:len(conv_labels), :, :, :]\n",
    "eval_data = eval_data[0:len(conv_labels_eval), :, :, :]\n",
    "print('Data is initaly structured in blocks')\n",
    "print(conv_labels)\n",
    "# Shuffle the data\n",
    "conv_labels, data = shuffle(conv_labels, data)\n",
    "conv_labels_eval, eval_data = shuffle(conv_labels_eval, eval_data)\n",
    "print('Data after shuffeling')\n",
    "print(conv_labels)\n",
    "\n",
    "# These are some commented lines that are not needed when loading files from github\n",
    "# def load_images(folder,N):\n",
    "#     np.random.seed(9001)\n",
    "#     image_folders = os.listdir(folder)\n",
    "#     image_names = os.listdir(folder + image_folders[0])\n",
    "#     number_of_images = 0\n",
    "    \n",
    "#     for label in image_folders:\n",
    "#         number_of_images += len(os.listdir(folder + label))\n",
    "#     data = np.zeros((N*len(image_folders), 224, 224, 3), dtype='float32')\n",
    "    \n",
    "#     labels = []\n",
    "#     i = 0\n",
    "#     for label in image_folders:\n",
    "#         im_in_label = os.listdir(folder + label)\n",
    "#         for image_name in im_in_label[:N]:\n",
    "#             img = image.load_img(folder + label + '/' + image_name, target_size=(224, 224))\n",
    "#             img2 = np.array(img)\n",
    "#             img3 = img2 + int(np.random.random()*100-50)\n",
    "#             np.clip(img3, 0, 255,out=img3)\n",
    "#             img3 = img3/255.\n",
    "#             data[i, :, :, :] =img3\n",
    "#             labels.append(label)\n",
    "#             i+=1\n",
    "\n",
    "#     return data, labels\n",
    "\n",
    "# data, data_labels = load_images(\"./handTracking/Images/\",800)#\n",
    "# eval_data, eval_labels = load_images(\"./handTracking/EvaluationImages/\",200)\n",
    "\n",
    "# # Convert labels from strings to numbers\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# le.fit(data_labels)\n",
    "# conv_labels = le.transform(data_labels) \n",
    "# conv_labels_eval = le.transform(eval_labels)\n",
    "\n",
    "\n",
    "# # Delete images that are just zeros\n",
    "# data = data[0:len(conv_labels), :, :, :]\n",
    "# eval_data = eval_data[0:len(conv_labels_eval), :, :, :]\n",
    "# print('Data is initaly structured in blocks')\n",
    "# print(conv_labels)\n",
    "# # Shuffle the data\n",
    "# conv_labels, data = shuffle(conv_labels, data)\n",
    "# conv_labels_eval, eval_data = shuffle(conv_labels_eval, eval_data)\n",
    "# print('Data after shuffeling')\n",
    "# print(conv_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a pretrained model\n",
    "To save some time during the lab we load a pretrained model. That model setup is included in the bottom of this notebook to show the concept of adding layers to a previously trained model. \n",
    "\n",
    "This model adds a few layers on top of the vgg16 model included in Keras. The training cycle after adding the extra layers took approx 1h on a laptop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model disk\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "GlobalMaxPooling (GlobalAver (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 15,242,565\n",
      "Trainable params: 527,877\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "# These first tree lines are used with github\n",
    "with urllib.request.urlopen('https://github.com/simjoh/AI-Lab-Neural-Net-and-Python/blob/master/handTracking/model.json?raw=true') as url:\n",
    "    json_file2 = json.loads(url.read().decode())\n",
    "    loaded_model_json = json.dumps(json_file2)\n",
    "\n",
    "# These two lines are used if you want to use a local json\n",
    "# json_file = open('./handTracking/model.json', 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "\n",
    "# json_file.close()\n",
    "loaded_model = tf.keras.models.model_from_json(loaded_model_json)\n",
    "\n",
    "\n",
    "# load weights into new model from github\n",
    "h5_file=tf.keras.utils.get_file(\n",
    "    './model.h5',\n",
    "    'https://github.com/simjoh/AI-Lab-Neural-Net-and-Python/blob/master/handTracking/model.h5?raw=true')\n",
    "loaded_model.load_weights(h5_file)\n",
    "\n",
    "# load weights into new model from local\n",
    "#loaded_model.load_weights(\"./handTracking/model.h5\")\n",
    "print(\"Loaded model disk\")\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Exercise\n",
    "Read the model above and discuss how someone came up with this setup?\n",
    "\n",
    "Hoe does the GlobalMaxPooling change image properties?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_eval = loaded_model.predict(eval_data, batch_size=24)\n",
    "pred_lab_eval = np.argmax(pred_eval, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_errors(eval_data, le.inverse_transform(conv_labels_eval), le.inverse_transform(pred_lab_eval), 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names= np.unique(conv_labels_eval)\n",
    "plot_confusion_matrix(conv_labels_eval, np.argmax(pred_eval, axis=1), classes=le.classes_, normalize=True,\n",
    "                      title='Normalized confusion matrix',fig_size=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue training\n",
    "Do some further training and see how the prediction changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize the number of epochs and batch size\n",
    "EPOCHS = 1\n",
    "BS = 16\n",
    "\n",
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
    "                        width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
    "                        horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "loaded_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"]) \n",
    "# Note that 10 epochs takes approx 1,5h...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = loaded_model.fit_generator(aug.flow(data, conv_labels, batch_size=BS),\n",
    "                               validation_data=(eval_data , conv_labels_eval), \n",
    "                               steps_per_epoch=len(data) // BS,\n",
    "                               epochs=EPOCHS)\n",
    "\n",
    "# serialize model to JSON\n",
    "#model_json = loaded_model.to_json()\n",
    "#with open(\"./handTracking/continued_model.json\", \"w\") as json_file:\n",
    "#    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "#loaded_model.save_weights(\"./handTracking/continued_model.h5\")\n",
    "#print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_pred_eval = loaded_model.predict(eval_data, batch_size=2)\n",
    "loaded_pred_lab_eval = np.argmax(loaded_pred_eval, axis=1)\n",
    "print(conv_labels_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names= np.unique(conv_labels_eval)\n",
    "plot_confusion_matrix(conv_labels_eval, np.argmax(loaded_pred_eval, axis=1), classes=le.classes_, normalize=True,\n",
    "                      title='Normalized confusion matrix',fig_size=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Look at the filters in the first layer of the vgg16 net. How do they look? Random or structured?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building on top of VGG16 model\n",
    "In this notebook we have loaded a previously trained model. The procedure of loading a trained model and adding layers to that model is described in the cell below.\n",
    "\n",
    "Working with complex deep learning classification tasks of images without using a previusly trained model is a good way of wasting time. Training the VGG16 model takes a few weeks on an ordinary computer while loading it takes a few seconds.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the VGG16 network, ensuring the head FC layer sets are left\n",
    "# off\n",
    "\n",
    "vgg16 = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "#Lock the VGG model parameters\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "headModel = vgg16.output\n",
    "headModel = GlobalAveragePooling2D(name=\"GlobalMaxPooling\", data_format='channels_last')(headModel)\n",
    "headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.3)(headModel)\n",
    "headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.3)(headModel)\n",
    "headModel = Dense(5, activation=\"softmax\")(headModel)#\n",
    "\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=vgg16.input, outputs=headModel)\n",
    "model.summary()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "###\n",
    "\n",
    "# # initialize the number of epochs and batch size\n",
    "EPOCHS = 10\n",
    "BS = 16\n",
    " \n",
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
    "                        width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
    "                        horizontal_flip=True, fill_mode=\"nearest\")\n",
    " \n",
    "# train the network \n",
    "# Note that 10 epochs takes approx 1,5h....\n",
    "H = model.fit_generator(aug.flow(data, conv_labels, batch_size=BS),\n",
    "                        validation_data=(eval_data , conv_labels_eval), steps_per_epoch=len(data) // BS,\n",
    "                        epochs=EPOCHS)\n",
    "# summarize history for accuracy\n",
    "f,ax=plt.subplots(1,2,figsize=(12,4))\n",
    "ax[0].plot(H.history['accuracy'], label='train')\n",
    "ax[0].plot(H.history['val_accuracy'], label='test')\n",
    "ax[0].set_title('Model accuracy')\n",
    "ax[0].set_ylabel('accuracy')\n",
    "ax[0].set_xlabel('epoch')\n",
    "ax[0].legend()\n",
    "\n",
    "# summarize history for loss\n",
    "ax[1].plot(H.history['loss'], label='train')\n",
    "ax[1].plot(H.history['val_loss'], label='test')\n",
    "ax[1].set_title('Model loss / cost')\n",
    "ax[1].set_ylabel('loss')\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[0].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Try to make your own model and let it train for a few epochs and see if you can achive better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "As is this model might not be very useful. Can you think of any modifications that turns it into value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
